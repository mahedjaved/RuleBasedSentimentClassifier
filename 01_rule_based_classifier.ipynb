{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlib_inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import random;\n",
    "from matplotlib import pyplot as plt;\n",
    "%matplotlib_inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Takes the input `X` and returns the label `1`\n",
    "* If the sentiment of text is positive `+1`\n",
    "* The label is `0` if the sentiment of text is `NEUTRAL` \n",
    "* The label is `-1` if the sentiment of text is `NEGATIVE`\n",
    "* The `Stanford Sentiment Treebank` allows us to test the accuracy of your classifier\n",
    "* The classifier works by assigning `positive`, `negative`, or `neutral` label is ...\n",
    "* ... by calculating the `dot product` => `feature_weights * extract_features(X)`\n",
    "* ... and if the value is `greater than zero`, return `1`\n",
    "* if it is `less than zero` return `-1`, and if exactly `zero` return `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func-1 -- Extracts dictionary of featured values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X):\n",
    "    features = {};\n",
    "    X_split = X.split(' ');\n",
    "\n",
    "    # count the number of \"good works\" and \"bad words\" in text\n",
    "    good_words = ['love', 'good'];\n",
    "    bad_words = ['hate', 'bad'];\n",
    "\n",
    "    # split the inputs\n",
    "    for x in X_split:\n",
    "        if x in good_words:\n",
    "            features['good_word_count'] = features.get('good_word_count', 0) + 1;\n",
    "        if x in bad_words:\n",
    "            features['bad_word_count'] = features.get('bad_word_count', 0) + 1;\n",
    "\n",
    "    # the \"bias\" value is always one, to allow us to assign a \"default\" score to the text\n",
    "    features['bias'] = 1;\n",
    "\n",
    "    return features;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func-3--: Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from training and dev\n",
    "def readXYdata(filename):\n",
    "    X_data = [];\n",
    "    Y_data = [];\n",
    "\n",
    "    # open the text file\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.strip().split(' ||| ');\n",
    "            X_data.append(text);\n",
    "            # convert the labels into integer\n",
    "            Y_data.append(int(label));\n",
    "    return X_data, Y_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func-4--: Run the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(X):\n",
    "    score = 0;\n",
    "    for feat_name, feat_value in extract_features(X).items():\n",
    "        score = score + feat_value * feature_weights.get(feat_name, 0);\n",
    "\n",
    "        # check if score is greater than 0, -1 or +1\n",
    "        if score > 0:\n",
    "            return 1;\n",
    "        elif score < 0:\n",
    "            return -1;\n",
    "        elif score:\n",
    "            return 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func-5--: Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(X_data, Y_data):\n",
    "    total_number = 0;\n",
    "    correct_number = 0;\n",
    "\n",
    "    # loop through the database (both x and y)\n",
    "    for X, Y in zip(X_data, Y_data):\n",
    "        # get prediction from the classifier\n",
    "        Y_pred = run_classifier(X);\n",
    "        total_number += 1;\n",
    "        # check if the prediction matches the labels\n",
    "        if Y == Y_pred:\n",
    "            correct_number += 1;\n",
    "    return correct_number / float(total_number);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func-6--: Find the errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_errors(X_data, Y_data):\n",
    "    error_ids = [];\n",
    "    Y_preds = [];\n",
    "    \n",
    "    # loop through the data and get predictions\n",
    "    for i, (X, Y) in enumerate(zip(X_data, Y_data)):\n",
    "        Y_preds.append(run_classifier(X));\n",
    "\n",
    "        # if the predictions dont match, append in error array\n",
    "        if Y != Y_preds[-1]:\n",
    "            error_ids.append(i);\n",
    "\n",
    "    # loop through errors array\n",
    "    for _ in range(5):\n",
    "        my_id = random.choice(error_ids);\n",
    "        X, Y, Y_pred = X_data[my_id], Y_data[my_id], Y_preds[my_id];\n",
    "        print(f'{X}\\ntrue label: {Y}\\npredicted label: {Y_pred}\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxxxxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\MAINPAPERWORK\\THE_NEW_AI_Redemption\\AdvancedNLP_CMUCS11-711\\CODE\\01_rule_based_classifier.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/MAINPAPERWORK/THE_NEW_AI_Redemption/AdvancedNLP_CMUCS11-711/CODE/01_rule_based_classifier.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xxxxxx\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xxxxxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set feature weights :: a dictionary which will assign a weight to each extracted feature.\n",
    "feature_weights = {\n",
    "    'good_word_count' : 1.0,\n",
    "    'bad_word_count' : -1.0,\n",
    "    'bias' : 0.5};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = readXYdata('../anlp-code/data/sst-sentiment-text-threeclass/train.txt');\n",
    "X_test, Y_test = readXYdata('../anlp-code/data/sst-sentiment-text-threeclass/dev.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.43387172284644193\n",
      "Dev/test accuracy: 0.4187102633969119\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calculate_accuracy(X_train, Y_train)\n",
    "test_accuracy = calculate_accuracy(X_test, Y_test)\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Dev/test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Difference between labels and predictions\n",
      "Makes a joke out of car chases for an hour and then gives us half an hour of car chases .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "[info] Difference between labels and predictions\n",
      "It dabbles all around , never gaining much momentum .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "[info] Difference between labels and predictions\n",
      "A rude black comedy about the catalytic effect a holy fool has upon those around him in the cutthroat world of children 's television .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n",
      "[info] Difference between labels and predictions\n",
      "The film favors the scientific over the spectacular -LRB- visually speaking -RRB- .\n",
      "true label: 0\n",
      "predicted label: 1\n",
      "\n",
      "[info] Difference between labels and predictions\n",
      "Though Jones and Snipes are enthralling , the movie bogs down in rhetoric and clichÃ© .\n",
      "true label: -1\n",
      "predicted label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find any errors\n",
    "find_errors(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('airdemp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3510ac267af34940b9bcbbea985f5687fcfe104f17d647513e4866477d6e8fb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
